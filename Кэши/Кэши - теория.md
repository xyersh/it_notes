
## Глоссарий
- **Cache miss** - промах кэша, запрошенный ключ не найден в кэше
- **Cache hit** - попадание в кэш, запрошенный ключ найден к кэше 
					(`Hit Ratio + Cache Miss Rate=1`)
- **Hit ratio(rate)** - процент попадания запросов в кэш, характеризует эффективность кэширования
- **throughout** - пропускная способность кэша
- **Горячий ключ** - ключ, на который приходится большая часть запросов
- **Прогрев кэша** - процесс наполнения кэша данными
- **Инвалидация** - удаление кэшированных данных
- **Политика вытеснения кэша** - принцип, по которому будут вытесняться элементы кэша при его переполнении
- **Стратегии кэширования** — это правила, по которым система решает, когда записывать данные в **кэш** (быстрое временное хранилище) и когда запрашивать их из **основного хранилища** (например, базы данных).
- **TTL** - (time to leave) - каждая запись истекает через заданный промежуток времени. Просто, но до момента истечения может возвращаться устаревшая информация
## Назначение кэшей:
- сокращение responce time сервисов
- сокращение нагрузки на сторонние сервисы
- переиспользование ранее полученных данных
- стабилизация работы приложении при кратковременных отказах систем



## Какие данные кэшировать?

| Ситуация                               | Как поступать                             |
| -------------------------------------- | ----------------------------------------- |
| Данные часто меняются(секунды)         | нет смысла добавлять такие данные в кэш   |
| Данные меняются нечасто (минуты, часы) | возможно, стоит дабавить эти данные в кэш |
| Меняются редко (дни, недели....)       | можно спокойно кэшировать эти данные      |

Можно кэшировать ошибки. Например, можно кэшировать факт отсутствия пользователя , и далее - просто отбиваться кэшом, а не проходить всякие контроли, как для запросов с валидными данными. 


## Эффективность кэширования

Формула определения среднего времени доступа к кэшу:
```
AverageTime = DBAccessTime *  CacheMissRate + CacheAccessTime
```
Где:
DBAccessTime - время запроса  к БД
CacheMissRate - показатель  промахов кэша
CacheAccessTime - время при обращении к кэшу

Принцип - чем значение у **AverageTime**  меньше **DBAccessTime** - тем лучше

Допустим:
**DBAccessTime** = 100ms
**CacheAccessTime** = 20ms
Тогда при **CacheMissRate** > 0.8 применение кэша будет нецелесообразно. Так как в этом случае **AverageTime** > **DBAccessTime** 


## Фундаментальные принципы эффективности  кэшей

1. **Пространственная локальность:** Если элемент данных используется, то вероятно, что элементы, расположенные рядом с ним в памяти, также будут использоваться в ближайшее время. Кэши используют это, загружая целые блоки данных (кэш-линии) вместо отдельных элементов.
    
2. **Временная локальность:** Если элемент данных был использован недавно, то велика вероятность, что он будет использован снова в ближайшем будущем. Кэши хранят недавно использованные данные, чтобы их можно было быстро получить.

## Виды кэширования
- **Внутреннее кэширование** - сюда относятся кэши, реализованных в различных структурах самих ЯП, на которых пишется приложение.
	- ### Плюсы:
		- Высокая скорость 
		- Отсутствие сетевых запросов
		- Нет расходов на сериализацию/десериализацию данных
	- ### Минусы
		- Горизонтальное масштабирование затруднительно
		- Прогрев кэша после  падения сервиса
- **Внешнее кэширование** - выделение кэша в отдельный сервис 
	- ### Плюсы
		- Хранение большого объемы данных
		- Простое горизонтальное масштабирование
		- После падения сервиса кэш не теряется
		- Простой прогрев кэша и простая логика инвалидации
	- ### Минусы
		- Скорость работы


## Основные метрики кэщширования
- **Объем памяти**, выделенной под кэш. Это базовый показатель, по которому можно судить, сколько используется ресурсов
- **RPS чтения/записи** – количество операций чтения/записи за единицу времени. В обычной ситуации количество операций чтения должно быть в разы больше количества операций записи. Обратное соотношение свидетельствует о проблемах в работе кэша
- **Количество элементов** в кэше. Его полезно знать в дополнение к объему памяти, чтобы обнаруживать большие записи
- **Hit rate** – процент извлечения данных из кэша. Чем он ближе к 100%, тем лучше. Этот параметр буквально определяет то, насколько наш кэш полезен и эффективен
- **Expired rate** – процент удаления записей по истечении TTL. Этот показатель помогает обнаружить проблемы с производительностью, вызванные большим количеством записей с одновременно истекшим TTL
- **Eviction rate** – процент вытеснения записей из кэша при достижении лимита используемой памяти. Важный показатель при выборе стратегий вытеснения.


## Политики вытеснения кэша (Cache Replacement Policies)

### LRU (Least Recently Used - Наименее недавно используемый)
- **Принцип:** Удаляет элемент, который не использовался дольше всех.
- **Логика:** Основывается на предположении, что если элемент не использовался в течение длительного времени, то он, скорее всего, не понадобится в ближайшем будущем.
- **Преимущества:** Считается одной из наиболее эффективных политик, так как хорошо использует принцип временной локальности.
- **Недостатки:** Требует отслеживания времени последнего использования для каждого элемента, что может быть вычислительно затратно (например, с помощью счетчиков или связанных списков).

### LFU (Least Frequently Used - Наименее часто используемый) 
- **Принцип:** Удаляет элемент, который использовался наименьшее количество раз.
- **Логика:** Предполагает, что редко используемые элементы менее важны и их можно удалить.
- **Преимущества:** Хорошо подходит для сценариев, где некоторые данные используются очень часто, а другие — очень редко.
- **Недостатки:** Может быть неоптимальной, если элемент был очень популярен в прошлом, но сейчас больше не нужен (например, пик запросов на новость, которая уже устарела). Также требует отслеживания счетчика использования для каждого элемента.

### FIFO (First-In, First-Out - Первый вошел, первый вышел)
- **Принцип:** Удаляет элемент, который был добавлен в кэш первым.
- **Логика:** Работает как очередь — самый старый элемент вытесняется первым.
- **Преимущества:** Проста в реализации.
- **Недостатки:** Не учитывает ни частоту, ни недавность использования. Элемент, который активно используется, но был добавлен давно, может быть вытеснен.

### MRU (Most Recently Used - Наиболее недавно используемый)
- **Принцип:** Удаляет элемент, который использовался совсем недавно.
- **Логика:** Противоположна LRU. В большинстве случаев неэффективна для общего кэширования.
- **Применение:** Может быть полезна в специфических сценариях, например, при циклическом сканировании очень больших наборов данных, где каждый элемент используется только один раз, а затем сразу же вытесняется, чтобы освободить место для следующего.

### Random (Случайный)
- **Принцип:** Случайно выбирает элемент для удаления.
- **Логика:** Отсутствует какая-либо сложная логика предсказания.
- **Преимущества:** Очень проста в реализации.
- **Недостатки:** Неоптимальна, так как не использует принципы локальности, что приводит к низкому коэффициенту попаданий.

### Другие (более сложные или специализированные) политики:
- **ARC (Adaptive Replacement Cache):** Более сложная политика, которая пытается адаптироваться к изменяющимся шаблонам доступа, комбинируя идеи LRU и LFU. Она поддерживает две очереди: одну для недавно использованных элементов и одну для часто используемых.
- **LIRS (Low Inter-reference Recency Set):** Еще более сложная политика, которая фокусируется на "недавности междоступов" (inter-reference recency) для принятия решений о вытеснении.
- **Segmented LRU (SLRU):** Разделяет кэш на сегменты (например, "горячий" и "теплый") и перемещает элементы между ними в зависимости от их использования.



## Стратегии кэширования

Они нужны, чтобы обеспечить высокую скорость работы: если данные есть в кэше, система берёт их оттуда, минуя медленное основное хранилище.

Вы можете использовать описанные стратегии в любых комбинациях. Например, вы можете взять опережающие кэширование, добавить туда сквозную запись и чтение на стороне, чтобы добиться максимальный актуальности данных и избежать промахов по максимуму!

### Cache through (Сквозное кэширование)

В рамках этой этой стратегии все запросы от приложения проходят через кэш. В коде это может выглядеть как связующее звено или “декоратор” над основным хранилищем. Таким образом, для приложения кэш и основная БД выглядят как один компонент хранилища.
**Преимущества**:
- Очень простая схема работы с точки зрения организации кода
- В коде легко добавить/убрать кэш, так как обычно это простая “обертка” над основным хранилищем
**Недостатки**:
- Схема негибкая, поскольку записывать в кэш мы можем строго после выполнения основного запроса и в целом кэш скрыт от бизнес-логики
#### Read through (Сквозное чтение)
![[32a18d4cc27f7adf65d94bdf403eca36.png]]
1. Приходит запрос на получение данных
2. Пытаемся прочитать данные из кэша
3. В кэше нужных данных нет, происходит промах (miss)
4. Кэш перенаправляет запрос в БД. Это важный нюанс стратегии: к БД обращается именно кэш, а не приложение
5. Хранилище отдает данные
6. Сохраняем данные в кэш
7. Отдаем запрошенные данные приложению. Для приложения это выглядит так, как если бы хранилище просто вернуло ему данные, то есть шаги 3-6 скрыты от основной бизнес-логики
8. Возвращаем результат запроса

#### Write through (Сквозная запись)
![[1ff3968bda1e513447463ebb1cb46bba.png]]
1. Приходит запрос на вставку каких-либо данных
2. Отправляем запрос на запись через кэш. В этот момент кэш выступает только как прокси и сам по себе ничего не делает
3. Сохраняем данные в БД
4. БД возвращает результат запроса
5. Сохраняем данные в кэш. Делаем мы это специально после вставки, чтобы кэш и БД были консистентны. Если бы мы писали данные в кэш на шаге 2, а при этом на шаге 3 произошла бы ошибка, то кэш содержал бы данные, которых нет в БД, что может привести к печальным последствиям
6. Отдаем запрошенные данные приложению
7. Возвращаем результат запроса
    


###  Cache aside (Кэширование на стороне) 
В этой стратегии, приложение координирует запросы в кэш и БД и само решает, куда и в какой момент нужно обращаться. В коде это выглядит как два хранилища: одно постоянное, второе – временное.
**Преимущества**:
- Гибкость. Управление полностью в руках приложения. Оно может сохранить данные в кэш сразу после обращения к БД, а может предварительно сделать еще ряд манипуляций с данными и только затем сохранить их в БД

**Недостатки**:
- Схема работы немного сложнее с точки зрения организации кода
- В коде сложнее добавить/убрать кэш, поскольку это отдельный компонент, с которым взаимодействует бизнес-логика. Изменить этого взаимодействие может быть сложно

#### Read aside (Чтение на стороне)
 ![[f4e0345f69cbabe1c7fef63e0b0b5efa.png]]
1. Приходит запрос на получение данных
2. Пытаемся читать из кэша
3. В кэше нужных данных нет, происходит промах (miss)
4. Приложение само обращается к хранилищу. В этом главное отличие от сквозного подхода: бизнес-логика в любой момент времени сама решает, куда обращаться – к кэшу или к БД
5. БД отдает данные
6. Сохраняем данные в кэш
7. Возвращаем результат запроса

#### Write aside  (Запись на стороне)
1. Приходит запрос на вставку каких-либо данных
2. Сохраняем данные в БД
3. БД возвращает результат запроса
4. Сохраняем данные в кэш. Опять-таки, мы намеренно делаем это после вставки, чтобы кэш и БД были консистентны. Сохранение данных в кэше перед шагом 2 и ошибка на шаге 2 привели бы к появлению в кэше данных, которых нет в БД. Результат был бы все тот же – печальные последствия
5. Возвращаем результат запроса
![[16d9a4af1917242c969b4f4cc01771e0.png]]



### Cache ahead (Опережающие кэширование)

Эта стратегия предназначена только для запросов на чтение. Они **всегда идут только** в кэш, никогда не попадая в БД напрямую. По факту мы работаем со снимком состояния БД и обновляем его с некоторой периодичностью. Для приложения это выглядит просто как хранилище, как и в случае со сквозным кэшированием.


![[737df2c61d03b05596f070f51560ea14.png]]

1. Входящие запросы на чтение:
    1. Приходит запрос на получение данных
    2. Читаем из кэша. Если в кэше нет нужных данных, то возвращаем ошибку. К БД в случае промаха не обращаемся
    3. Если данные есть, то отдаем их приложению
    4. Возвращаем результат запроса
        
2. Обновление кэша:
    1. Периодически запускается фоновый процесс, который читает данные из БД.
    2. Читаем актуальные данные из БД
    3. БД отдает данные
    4. Сохраняем данные в кэш
        

Преимущества:
- Минимальная и полностью контролируемая нагрузка на БД. Клиентские запросы не могут повлиять на БД
- В коде легко добавить/убрать кэш, поскольку можно просто заменить кэш на основное хранилище и обращаться уже к нему
- Простота, так как не приходится иметь дело с двумя хранилищами
    

Недостатки:
- Кэш отстает от основного хранилища на период между запусками обновления кэша. Нужно помнить, что на момент обращения свежие данные могут еще “не доехать” до кэша. Эта проблема может быть решена использованием сквозной записи или записи на стороне. Тогда, при обновлении данных в БД, данные будут обновляться и в кэше


### Инвалидация по TTL

**TTL (Time To Live)** – время жизни данных в кэше. При сохранении данных в кэш для них устанавливается TTL и данные будут обновляться с периодичностью не менее TTL. 

Это самый простой способ инвалидации данных. Тем не менее, у этой стратегии есть свои подводные камни.

Самый главный из них – вопрос длительности TTL. Если TTL слишком короткий, то запись может “протухнуть” и стать недействительной раньше, чем обновление было бы необходимо, что приведет к отправке повторного запроса в источник данных. Если TTL слишком длинный, то запись может содержать устаревшие данные, что может привести к ошибкам или неправильной работе приложения. Обычно ответ на этот вопрос подбирается эмпирическим путем. 

Есть, впрочем, и другой вариант. Источник данных может присылать TTL сам, тогда клиенту не придется выбирать TTL, а просто брать предлагаемый. Такой подход, например, можно использовать в HTTP.

Сложность иного рода возникает, если записи становятся недействительными одновременно в большом количестве. В таком случае возникает множество запросов в источник данных, что может привести к проблемам с производительностью, а то и вовсе “положить” его. Для избежания подобной ситуации, можно использовать jitter.

**Jitter** – это случайное значение, добавляемое к TTL. Если в обычном случае все записи имеют, например, TTL = 60 сек., то при использовании jitter с диапазоном от 0 до 10 сек. TTL будет принимать значение от 60 до 70 сек. Это позволит сгладить количество записей, переходящих в состояние недействительных одновременно.

Jitter позволил нам сгладить нагрузку на источник данных, когда “протухает” много записей сразу. Но что делать, если есть одна запись, которую интенсивно используют? Ее инвалидация приведет к тому, что все запросы, которые не нашли данных в кэше, одновременно обратятся к источнику. Тогда нам нужно схлопнуть все эти запросы в один. В go есть для этого отличная библиотека [singleflight](https://pkg.go.dev/golang.org/x/sync/singleflight). Она определяет одинаковые запросы, возникающие одномоментно, выполняет лишь один запрос в источник, а затем отдает результат всем изначальным запросам. Таким образом, если у нас возникли десять запросов, библиотека выполнит только один из них, а результат вернет всем десяти. Стоит отметить, что эта библиотека работает только в рамках одного экземпляра приложения. Если у вас их несколько, то даже с использованием этой библиотеки в источник может уйти больше одного запроса.



## Кэширование ошибок


Представим себе, что клиент запрашивает данные, которых нет в источнике. Пусть это будем информация о товаре по id. Казалось бы, нет данных и ладно: просто сходим в источник, ничего не получим и сообщим клиенту. Но что, если таких запросов много? А что, если кто-то делает это специально?

Это типичная схема так называемой атаки через промахи кэша (**cache miss attack**). Ее суть в запрашивании данных, которых заведомо не может быть в кэше, поскольку их нет в источнике. Вал таких запросов может привести к проблемам с производительностью источника и даже к его “падению”. Этого можно избежать, если кэшировать ошибку, тогда последующие запросы того же рода будут попадать в кэш и источник не пострадает.

Но тут тоже нужно быть осторожным. Если хранить в одном кэше и полезные данные, и ошибки, то в случае атаки полезные данные могут вытеснены из кэша. Поэтому я бы рекомендовал иметь выделенный кэш под ошибки. Он может быть меньшего объема, чем основной кэш.

Также кэширование ошибок полезно, если сервис, к которому вы обращаетесь, “почувствовал себя плохо”. Чтобы не забивать его запросами, которые, скорее всего, не будут выполнены, а лишь усугубят проблему, лучше кэшировать ошибки на несколько секунд. Таким образом, мы перестанем оказывать негативное воздействие на сервис и дадим ему возможность нормализоваться. Но с этой задачей лучше справляется паттерн **Circuit Breaker**, который мы не будем рассматривать в рамках этой статьи.