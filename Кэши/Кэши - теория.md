
## Глоссарий
- **Cache miss** - промах кэша, запрошенный ключ не найден в кэше
- **Cache hit** - попадание в кэш, запрошенный ключ найден к кэше 
					(`Hit Ratio + Cache Miss Rate=1`)
- **Hit ratio(rate)** - процент попадания запросов в кэш, характеризует эффективность кэширования
- **throughout** - пропускная способность кэша
- **Горячий ключ** - ключ, на который приходится большая часть запросов
- **Прогрев кэша** - процесс наполнения кэша данными
- **Инвалидация** - удаление кэшированных данных
- **Политика вытеснения кэша** - принцип, по которому будут вытесняться элементы кэша при его переполнении
- **Стратегии кэширования** — это правила, по которым система решает, когда записывать данные в **кэш** (быстрое временное хранилище) и когда запрашивать их из **основного хранилища** (например, базы данных).
- **TTL** - (time to leave) - каждая запись истекает через заданный промежуток времени. Просто, но до момента истечения может возвращаться устаревшая информация
## Назначение кэшей:
- сокращение responce time сервисов
- сокращение нагрузки на сторонние сервисы
- переиспользование ранее полученных данных
- стабилизация работы приложении при кратковременных отказах систем



## Какие данные кэшировать?

| Ситуация                               | Как поступать                             |
| -------------------------------------- | ----------------------------------------- |
| Данные часто меняются(секунды)         | нет смысла добавлять такие данные в кэш   |
| Данные меняются нечасто (минуты, часы) | возможно, стоит дабавить эти данные в кэш |
| Меняются редко (дни, недели....)       | можно спокойно кэшировать эти данные      |

Можно кэшировать ошибки. Например, можно кэшировать факт отсутствия пользователя , и далее - просто отбиваться кэшом, а не проходить всякие контроли, как для запросов с валидными данными. 


## Эффективность кэширования

Формула определения среднего времени доступа к кэшу:
```
AverageTime = DBAccessTime *  CacheMissRate + CacheAccessTime
```
Где:
DBAccessTime - время запроса  к БД
CacheMissRate - показатель  промахов кэша
CacheAccessTime - время при обращении к кэшу

Принцип - чем значение у **AverageTime**  меньше **DBAccessTime** - тем лучше

Допустим:
**DBAccessTime** = 100ms
**CacheAccessTime** = 20ms
Тогда при **CacheMissRate** > 0.8 применение кэша будет нецелесообразно. Так как в этом случае **AverageTime** > **DBAccessTime** 


## Фундаментальные принципы эффективности  кэшей

1. **Пространственная локальность:** Если элемент данных используется, то вероятно, что элементы, расположенные рядом с ним в памяти, также будут использоваться в ближайшее время. Кэши используют это, загружая целые блоки данных (кэш-линии) вместо отдельных элементов.
    
2. **Временная локальность:** Если элемент данных был использован недавно, то велика вероятность, что он будет использован снова в ближайшем будущем. Кэши хранят недавно использованные данные, чтобы их можно было быстро получить.

## Виды кэширования
- **Внутреннее кэширование** - сюда относятся кэши, реализованных в различных структурах самих ЯП, на которых пишется приложение.
	- ### Плюсы:
		- Высокая скорость 
		- Отсутствие сетевых запросов
		- Нет расходов на сериализацию/десериализацию данных
	- ### Минусы
		- Горизонтальное масштабирование затруднительно
		- Прогрев кэша после  падения сервиса
- **Внешнее кэширование** - выделение кэша в отдельный сервис 
	- ### Плюсы
		- Хранение большого объемы данных
		- Простое горизонтальное масштабирование
		- После падения сервиса кэш не теряется
		- Простой прогрев кэша и простая логика инвалидации
	- ### Минусы
		- Скорость работы


## Основные метрики кэщширования
- **Объем памяти**, выделенной под кэш. Это базовый показатель, по которому можно судить, сколько используется ресурсов
- **RPS чтения/записи** – количество операций чтения/записи за единицу времени. В обычной ситуации количество операций чтения должно быть в разы больше количества операций записи. Обратное соотношение свидетельствует о проблемах в работе кэша
- **Количество элементов** в кэше. Его полезно знать в дополнение к объему памяти, чтобы обнаруживать большие записи
- **Hit rate** – процент извлечения данных из кэша. Чем он ближе к 100%, тем лучше. Этот параметр буквально определяет то, насколько наш кэш полезен и эффективен
- **Expired rate** – процент удаления записей по истечении TTL. Этот показатель помогает обнаружить проблемы с производительностью, вызванные большим количеством записей с одновременно истекшим TTL
- **Eviction rate** – процент вытеснения записей из кэша при достижении лимита используемой памяти. Важный показатель при выборе стратегий вытеснения.


## Политики вытеснения кэша (Cache Replacement Policies)

### LRU (Least Recently Used - Наименее недавно используемый)
- **Принцип:** Удаляет элемент, который не использовался дольше всех.
- **Логика:** Основывается на предположении, что если элемент не использовался в течение длительного времени, то он, скорее всего, не понадобится в ближайшем будущем.
- **Преимущества:** Считается одной из наиболее эффективных политик, так как хорошо использует принцип временной локальности.
- **Недостатки:** Требует отслеживания времени последнего использования для каждого элемента, что может быть вычислительно затратно (например, с помощью счетчиков или связанных списков).

### LFU (Least Frequently Used - Наименее часто используемый) 
- **Принцип:** Удаляет элемент, который использовался наименьшее количество раз.
- **Логика:** Предполагает, что редко используемые элементы менее важны и их можно удалить.
- **Преимущества:** Хорошо подходит для сценариев, где некоторые данные используются очень часто, а другие — очень редко.
- **Недостатки:** Может быть неоптимальной, если элемент был очень популярен в прошлом, но сейчас больше не нужен (например, пик запросов на новость, которая уже устарела). Также требует отслеживания счетчика использования для каждого элемента.

### FIFO (First-In, First-Out - Первый вошел, первый вышел)
- **Принцип:** Удаляет элемент, который был добавлен в кэш первым.
- **Логика:** Работает как очередь — самый старый элемент вытесняется первым.
- **Преимущества:** Проста в реализации.
- **Недостатки:** Не учитывает ни частоту, ни недавность использования. Элемент, который активно используется, но был добавлен давно, может быть вытеснен.

### MRU (Most Recently Used - Наиболее недавно используемый)
- **Принцип:** Удаляет элемент, который использовался совсем недавно.
- **Логика:** Противоположна LRU. В большинстве случаев неэффективна для общего кэширования.
- **Применение:** Может быть полезна в специфических сценариях, например, при циклическом сканировании очень больших наборов данных, где каждый элемент используется только один раз, а затем сразу же вытесняется, чтобы освободить место для следующего.

### Random (Случайный)
- **Принцип:** Случайно выбирает элемент для удаления.
- **Логика:** Отсутствует какая-либо сложная логика предсказания.
- **Преимущества:** Очень проста в реализации.
- **Недостатки:** Неоптимальна, так как не использует принципы локальности, что приводит к низкому коэффициенту попаданий.

### Другие (более сложные или специализированные) политики:
- **ARC (Adaptive Replacement Cache):** Более сложная политика, которая пытается адаптироваться к изменяющимся шаблонам доступа, комбинируя идеи LRU и LFU. Она поддерживает две очереди: одну для недавно использованных элементов и одну для часто используемых.
- **LIRS (Low Inter-reference Recency Set):** Еще более сложная политика, которая фокусируется на "недавности междоступов" (inter-reference recency) для принятия решений о вытеснении.
- **Segmented LRU (SLRU):** Разделяет кэш на сегменты (например, "горячий" и "теплый") и перемещает элементы между ними в зависимости от их использования.



## Стратегии кэширования

Они нужны, чтобы обеспечить высокую скорость работы: если данные есть в кэше, система берёт их оттуда, минуя медленное основное хранилище.

Вы можете использовать описанные стратегии в любых комбинациях. Например, вы можете взять опережающие кэширование, добавить туда сквозную запись и чтение на стороне, чтобы добиться максимальный актуальности данных и избежать промахов по максимуму!

### Cache through (Сквозное кэширование)

В рамках этой этой стратегии все запросы от приложения проходят через кэш. В коде это может выглядеть как связующее звено или “декоратор” над основным хранилищем. Таким образом, для приложения кэш и основная БД выглядят как один компонент хранилища.
**Преимущества**:
- Очень простая схема работы с точки зрения организации кода
- В коде легко добавить/убрать кэш, так как обычно это простая “обертка” над основным хранилищем
**Недостатки**:
- Схема негибкая, поскольку записывать в кэш мы можем строго после выполнения основного запроса и в целом кэш скрыт от бизнес-логики
#### Read through (Сквозное чтение)
![[32a18d4cc27f7adf65d94bdf403eca36.png]]
1. Приходит запрос на получение данных
2. Пытаемся прочитать данные из кэша
3. В кэше нужных данных нет, происходит промах (miss)
4. Кэш перенаправляет запрос в БД. Это важный нюанс стратегии: к БД обращается именно кэш, а не приложение
5. Хранилище отдает данные
6. Сохраняем данные в кэш
7. Отдаем запрошенные данные приложению. Для приложения это выглядит так, как если бы хранилище просто вернуло ему данные, то есть шаги 3-6 скрыты от основной бизнес-логики
8. Возвращаем результат запроса

#### Write through (Сквозная запись)
![[1ff3968bda1e513447463ebb1cb46bba.png]]
1. Приходит запрос на вставку каких-либо данных
2. Отправляем запрос на запись через кэш. В этот момент кэш выступает только как прокси и сам по себе ничего не делает
3. Сохраняем данные в БД
4. БД возвращает результат запроса
5. Сохраняем данные в кэш. Делаем мы это специально после вставки, чтобы кэш и БД были консистентны. Если бы мы писали данные в кэш на шаге 2, а при этом на шаге 3 произошла бы ошибка, то кэш содержал бы данные, которых нет в БД, что может привести к печальным последствиям
6. Отдаем запрошенные данные приложению
7. Возвращаем результат запроса
    


###  Cache aside (Кэширование на стороне) 
В этой стратегии, приложение координирует запросы в кэш и БД и само решает, куда и в какой момент нужно обращаться. В коде это выглядит как два хранилища: одно постоянное, второе – временное.
**Преимущества**:
- Гибкость. Управление полностью в руках приложения. Оно может сохранить данные в кэш сразу после обращения к БД, а может предварительно сделать еще ряд манипуляций с данными и только затем сохранить их в БД

**Недостатки**:
- Схема работы немного сложнее с точки зрения организации кода
- В коде сложнее добавить/убрать кэш, поскольку это отдельный компонент, с которым взаимодействует бизнес-логика. Изменить этого взаимодействие может быть сложно

#### Read aside (Чтение на стороне)
 ![[f4e0345f69cbabe1c7fef63e0b0b5efa.png]]
1. Приходит запрос на получение данных
2. Пытаемся читать из кэша
3. В кэше нужных данных нет, происходит промах (miss)
4. Приложение само обращается к хранилищу. В этом главное отличие от сквозного подхода: бизнес-логика в любой момент времени сама решает, куда обращаться – к кэшу или к БД
5. БД отдает данные
6. Сохраняем данные в кэш
7. Возвращаем результат запроса

#### Write aside  (Запись на стороне)
1. Приходит запрос на вставку каких-либо данных
2. Сохраняем данные в БД
3. БД возвращает результат запроса
4. Сохраняем данные в кэш. Опять-таки, мы намеренно делаем это после вставки, чтобы кэш и БД были консистентны. Сохранение данных в кэше перед шагом 2 и ошибка на шаге 2 привели бы к появлению в кэше данных, которых нет в БД. Результат был бы все тот же – печальные последствия
5. Возвращаем результат запроса
![[16d9a4af1917242c969b4f4cc01771e0.png]]



### Cache ahead (Опережающие кэширование)

Эта стратегия предназначена только для запросов на чтение. Они **всегда идут только** в кэш, никогда не попадая в БД напрямую. По факту мы работаем со снимком состояния БД и обновляем его с некоторой периодичностью. Для приложения это выглядит просто как хранилище, как и в случае со сквозным кэшированием.


![[737df2c61d03b05596f070f51560ea14.png]]

1. Входящие запросы на чтение:
    1. Приходит запрос на получение данных
    2. Читаем из кэша. Если в кэше нет нужных данных, то возвращаем ошибку. К БД в случае промаха не обращаемся
    3. Если данные есть, то отдаем их приложению
    4. Возвращаем результат запроса
        
2. Обновление кэша:
    1. Периодически запускается фоновый процесс, который читает данные из БД.
    2. Читаем актуальные данные из БД
    3. БД отдает данные
    4. Сохраняем данные в кэш
        

Преимущества:
- Минимальная и полностью контролируемая нагрузка на БД. Клиентские запросы не могут повлиять на БД
- В коде легко добавить/убрать кэш, поскольку можно просто заменить кэш на основное хранилище и обращаться уже к нему
- Простота, так как не приходится иметь дело с двумя хранилищами
    

Недостатки:
- Кэш отстает от основного хранилища на период между запусками обновления кэша. Нужно помнить, что на момент обращения свежие данные могут еще “не доехать” до кэша. Эта проблема может быть решена использованием сквозной записи или записи на стороне. Тогда, при обновлении данных в БД, данные будут обновляться и в кэше
     