**Rate Limiter** — паттерн реализации  защитного механизма, который контролирует количество запросов, которые клиент или пользователь может отправить к службе или ресурсу за определённый период времени. Его основная цель — предотвратить злоупотребление, обеспечить справедливость использования ресурсов и защитить систему от перегрузки.
Готовая реализация в Golang: golang.org/x/time/rate
### Основная Терминология

При работе с Rate Limiter'ом вы будете оперировать следующими ключевыми понятиями:
- **Лимит (Limit):** Максимально допустимое количество запросов в течение заданного **периода**. Например, 100 запросов.
- **Период (Period/Window):** Временной интервал, в течение которого применяется **лимит**. Например, 1 секунда, 1 минута или 1 час.
- **Блокировка / Отклонение (Throttling / Rejection):** Действие, предпринимаемое Rate Limiter'ом, когда клиент превышает свой лимит. Обычно это возврат HTTP-статуса **429 Too Many Requests**.
- **Идентификатор Клиента (Client Identifier):** Поле, используемое для отслеживания запросов, чтобы отличать одного клиента от другого. Это может быть **IP-адрес**, **токен API** или **ID пользователя**.
- **Разрешено (Allowed):** Статус запроса, который был обработан, так как он не превысил установленный лимит.
- **Оставшийся Лимит (Remaining Limit):** Количество запросов, которое клиент ещё может сделать до окончания текущего **периода**.

### Назначение и Использование

#### Для чего используется?

Паттерн Rate Limiter используется для решения следующих критических задач
1. **Защита от DoS/DDoS-атак:** Предотвращение исчерпания ресурсов сервера (ЦП, память, пропускная способность) путём ограничения количества запросов с одного источника.
2. **Управление трафиком (Traffic Shaping):** Обеспечение предсказуемой производительности и стабильности службы за счёт предотвращения "всплесков" трафика.
3. **Справедливое распределение ресурсов:** Гарантирование того, что один "шумный" клиент не "задушит" сервис для всех остальных пользователей.
4. **Контроль стоимости:** Ограничение использования платных сторонних API, чтобы избежать неожиданно высоких счетов.
5. **Борьба со скрапингом/ботами:** Затруднение автоматизированного сбора данных или попыток подбора паролей.
    

#### Где используется?

Rate Limiter должен быть установлен **перед всеми публичными точками входа (endpoint)** в вашей системе, особенно для:
- **API-шлюзов:** Для ограничения доступа к микросервисам.
- **Форм авторизации/регистрации:** Для предотвращения атак типа **Brute Force** (подбора паролей).
- **Платёжных операций:** Для предотвращения многократной отправки одного и того же запроса.
- **Высоконагруженных API-методов:** Например, `/api/search` или `/api/feed`, которые могут быть очень ресурсоёмкими.


#### **"Token Bucket"** - суть алгоритма:
- Представьте себе ведро определённой ёмкости (`burst`).
- В это ведро с постоянной скоростью (`limit`) добавляются "токены".
- Чтобы выполнить операцию, горутина должна взять один токен из ведра.
- Если токенов в ведре нет, горутина должна либо подождать, пока появится новый токен, либо получить отказ.
- Ёмкость ведра (`burst`) позволяет справляться с кратковременными всплесками активности. Например, если лимит — 2 запроса в секунду, а `burst` — 10, система может мгновенно обработать 10 запросов, а затем будет обрабатывать не более 2 в секунду.




#### **"Leaky Backet"** - суть алгоритма:
Представьте себе обычное ведро, у которого в дне есть небольшое отверстие.
	-  **Входящий поток (Запросы):** Вы льёте в это ведро воду. Вода — это входящие запросы к вашей системе. Вы можете лить её быстро (всплеск трафика) или медленно.
	- **Ведро (Очередь):** Ведро имеет ограниченный объём. Это очередь (буфер) для запросов.
	- **Отверстие (Процессор):** Через отверстие вода вытекает с **постоянной, неизменной скоростью**, независимо от того, сколько воды в ведре (лишь бы оно не было пустым). Это ваш обработчик, который обрабатывает запросы с фиксированной скоростью.
	- **Переполнение (Отклонение запросов):** Если вы льёте воду слишком быстро и ведро наполняется до краёв, новая вода просто переливается через край и теряется. Это отклоненные запросы, для которых не нашлось места в очереди.


#### Сравнение **Leaky Bucket** и **Token Bucket**

| Критерий                | Leaky Bucket (Дырявое ведро)                                                                | Token Bucket (Ведро с токенами)                                                                        |
| ----------------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **Основной принцип**    | Регулирует **скорость вывода** (outflow)                                                    | Регулирует **скорость ввода** (inflow)                                                                 |
| **Обработка всплесков** | **Сглаживает** всплески. Трафик на выходе всегда ровный                                     | **Позволяет** всплески. Можно мгновенно израсходовать все токены                                       |
| **Основной ресурс**     | Размер очереди для ожидания                                                                 | Количество токенов для разрешения                                                                      |
| **Результат**           | Трафик становится предсказуемым и равномерным                                               | Пропускная способность соответствует заданным лимитам, но допускает "пики"                             |
| **Идеально для...**     | Систем, где важна постоянная скорость потребления ресурсов (например, стриминг видео/аудио) | Классических API, где нужно ограничить среднюю скорость, но разрешить кратковременные пики активности. |





### ПРИМЕРЫ

#### Использование готовой реализации на Go (Алгоритм "Token Bucket")

Наиболее популярным и эффективным алгоритмом для Rate Limiter'а является **Token Bucket** (Ведро с токенами).
- **Идея:** Каждому клиенту выделяется "ведро" фиксированного размера. Токены, символизирующие право на запрос, добавляются в ведро с постоянной скоростью. Чтобы сделать запрос, клиент должен извлечь один токен. Если токенов нет, запрос отклоняется.
Ниже представлена реализация **Token Bucket** в Go с использованием пакета `golang.org/x/time/rate`, который часто используется для этой цели.

```go 
package main

import (
	"fmt"
	"log"
	"net/http"
	"time"

	"golang.org/x/time/rate" // Стандартная библиотека для Rate Limiting
)

// rateLimiterManager содержит мапу для хранения ограничителей для каждого клиента.
type rateLimiterManager struct {
	limiters map[string]*rate.Limiter
	rate     rate.Limit    // Скорость (количество событий в секунду)
	burst    int           // Размер "ведра" (максимальный всплеск)
}

// newRateLimiterManager создает новый менеджер ограничителей.
func newRateLimiterManager(r rate.Limit, b int) *rateLimiterManager {
	return &rateLimiterManager{
		limiters: make(map[string]*rate.Limiter),
		rate:     r,
		burst:    b,
	}
}

// getLimiter возвращает ограничитель для заданного IP-адреса.
// Если ограничителя нет, он создается и добавляется в мапу.
func (rlm *rateLimiterManager) getLimiter(ip string) *rate.Limiter {
	// 1. Поиск в мапе. Требуется блокировка для доступа к общей мапе.
	// В реальном приложении для потокобезопасности нужна sync.RWMutex.
	// Для простоты примера мы ее опускаем, но в продакшене это обязательно!
	
	limiter, exists := rlm.limiters[ip]
	if !exists {
		// 2. Если ограничителя нет, создаем новый с заданными параметрами.
		// rate.Every(time.Second/rlm.rate) - задает интервал пополнения.
		limiter = rate.NewLimiter(rlm.rate, rlm.burst)
		rlm.limiters[ip] = limiter
		// NOTE: В продакшене нужно добавить логику для очистки старых ограничителей (Garbage Collection).
	}
	return limiter
}

// rateLimitMiddleware - это middleware для обработки HTTP-запросов.
func (rlm *rateLimiterManager) rateLimitMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// 1. Получаем IP-адрес клиента. (Для продакшена нужна более надежная логика: X-Forwarded-For, RemoteAddr).
		clientIP := r.RemoteAddr

		// 2. Получаем или создаем Rate Limiter для этого IP.
		limiter := rlm.getLimiter(clientIP)

		// 3. Проверяем, разрешен ли запрос.
		// Allow() пытается извлечь один токен. Если токена нет, возвращает false.
		if !limiter.Allow() {
			// 4. Запрос отклонен: возвращаем статус 429 Too Many Requests.
			w.WriteHeader(http.StatusTooManyRequests)
			w.Write([]byte("429 Too Many Requests: Вы превысили лимит запросов."))
			return
		}

		// 5. Запрос разрешен: передаем управление следующему обработчику.
		next.ServeHTTP(w, r)
	})
}

// helloHandler - основной обработчик, который вызывается, если запрос разрешен.
func helloHandler(w http.ResponseWriter, r *http.Request) {
	fmt.Fprintf(w, "Привет, мир! Запрос обработан успешно.")
}

func main() {
	// Устанавливаем лимит: 5 запросов в секунду (5/s) с максимальным всплеском (burst) 10.
	// Это означает:
	// - 5 токенов добавляются каждую секунду.
	// - Клиент может сделать 10 запросов одновременно, если ведро полное.
	// - После этого он может делать 5 запросов в секунду.
	rlm := newRateLimiterManager(5, 10)

	// Создаем цепочку: Middleware -> Handler.
	handler := rlm.rateLimitMiddleware(http.HandlerFunc(helloHandler))

	// Запускаем сервер
	http.Handle("/", handler)
	log.Println("Сервер запущен на :8080. Лимит: 5req/s, Burst: 10.")
	log.Fatal(http.ListenAndServe(":8080", nil))
}

// Как проверить:
// Запустите сервер и в другом терминале быстро выполните команду:
// for i in {1..20}; do curl -s -o /dev/null -w "%{http_code}\n" http://localhost:8080/; done
// Вы увидите, что первые 10-11 запросов вернут 200, а последующие, сделанные слишком быстро, начнут возвращать 429.
```



#### Реализация алгоритма **TokenBucket**
Мы создадим структуру `TokenBucket`, которая будет хранить своё состояние:

- `capacity` — максимальное количество токенов.
- `tokens` — текущее количество токенов.
- `rate` — скорость пополнения (токенов в секунду).
- `lastTokenTime` — время последнего пополнения токенов.
- `mu` — мьютекс для безопасной работы в конкурентной среде.

Основная логика будет заключаться в том, чтобы перед каждой попыткой взять токен сначала вычислить, сколько новых токенов должно было накопиться со времени последней операции.

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

// TokenBucket представляет наше "ведро с токенами".
type TokenBucket struct {
	capacity      int64 // Максимальная емкость ведра (burst)
	tokens        int64 // Текущее количество токенов в ведре

	rate          int64     // Скорость пополнения (токенов в секунду)
	lastTokenTime time.Time // Время последнего пополнения токенов
	mu            sync.Mutex
}

// NewTokenBucket создает новое ведро с токенами.
// rate - количество токенов, добавляемых в секунду.
// capacity - максимальное количество токенов в ведре.
func NewTokenBucket(rate, capacity int64) *TokenBucket {
	if rate <= 0 || capacity <= 0 {
		return nil
	}
	return &TokenBucket{
		capacity:      capacity,
		tokens:        capacity, // Начинаем с полного ведра
		rate:          rate,
		lastTokenTime: time.Now(),
	}
}

// refill — внутренний метод для пополнения токенов.
// Он вычисляет, сколько времени прошло с последнего пополнения,
// и добавляет соответствующее количество токенов.
func (tb *TokenBucket) refill() {
	now := time.Now()
	// Вычисляем время, прошедшее с последнего пополнения
	duration := now.Sub(tb.lastTokenTime)

	// Вычисляем, сколько токенов нужно добавить.
	// Используем наносекунды для точности.
	tokensToAdd := (duration.Nanoseconds() * tb.rate) / 1e9 // 1e9 наносекунд = 1 секунда

	if tokensToAdd > 0 {
		// Добавляем новые токены
		tb.tokens += tokensToAdd
		// Убеждаемся, что количество токенов не превышает емкость
		if tb.tokens > tb.capacity {
			tb.tokens = tb.capacity
		}
		// Обновляем время последнего пополнения
		tb.lastTokenTime = now
	}
}

// Take пытается взять один токен из ведра.
// Возвращает true, если токен успешно взят, и false в противном случае.
// Это неблокирующая операция.
func (tb *TokenBucket) Take() bool {
	// Блокируем для безопасного доступа к состоянию
	tb.mu.Lock()
	defer tb.mu.Unlock()

	// Перед тем как взять токен, пополняем ведро
	tb.refill()

	// Проверяем, есть ли хотя бы один токен
	if tb.tokens >= 1 {
		tb.tokens--
		return true
	}

	return false
}

// --- Демонстрация работы ---
func main() {
	// Создаем ведро: 2 токена в секунду, максимальная емкость 5.
	bucket := NewTokenBucket(2, 5)

	fmt.Printf("Создано ведро: rate=2, capacity=5. Текущее время: %s\n\n", time.Now().Format("15:04:05"))

	// 1. Демонстрация "всплеска" (burst)
	// Пытаемся быстро взять 7 токенов. Первые 5 должны пройти успешно, т.к. ведро полное.
	fmt.Println("--- Попытка взять 7 токенов подряд (демонстрация capacity) ---")
	for i := 1; i <= 7; i++ {
		if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
	}
	fmt.Println("---------------------------------------------------------")

	// 2. Демонстрация пополнения
	// Ждем 1 секунду. За это время должны добавиться 2 новых токена (т.к. rate=2).
	fmt.Printf("\nЖдем 1 секунду... Время: %s\n", time.Now().Format("15:04:05"))
	time.Sleep(1 * time.Second)
	fmt.Printf("Прошла 1 секунда. Время: %s\n\n", time.Now().Format("15:04:05"))

	fmt.Println("--- Попытка взять 3 токена после паузы ---")
	// Теперь пытаемся взять 3 токена. Первые 2 должны пройти, третий - нет.
	for i := 1; i <= 3; i++ {
		if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
	}
	fmt.Println("---------------------------------------------------------")

    // 3. Демонстрация того, что емкость не превышается
	fmt.Printf("\nЖдем 3 секунды... Время: %s\n", time.Now().Format("15:04:05"))
    time.Sleep(3 * time.Second) // За 3 секунды должно сгенерироваться 3*2=6 токенов
	fmt.Printf("Прошло 3 секунды. Время: %s\n\n", time.Now().Format("15:04:05"))

    fmt.Println("--- Попытка взять 6 токенов после долгой паузы ---")
    // Хоть и сгенерировалось 6 токенов, в ведре их будет только 5 (макс. емкость)
    for i := 1; i <= 6; i++ {
        if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
    }
}
```

##### Разбор кода 
1. **`NewTokenBucket`**: Создаёт ведро и сразу же "наполняет" его до краёв (`tokens: capacity`). Это позволяет системе сразу же обработать всплеск запросов, равный ёмкости ведра.
2. **`refill()`**: Это самая важная часть. Она не запускается по таймеру, а вызывается "лениво" в момент запроса токена. Это эффективно, так как не тратит ресурсы, если система простаивает. Расчёт `(duration.Nanoseconds() * tb.rate) / 1e9` позволяет корректно обрабатывать любые промежутки времени и скорости.
3. **`Take()`**: Публичный метод. Он оборачивает логику в мьютекс, чтобы избежать гонок данных, вызывает `refill` для актуализации состояния и затем пытается взять токен.


#### Реализация алгоритма **Leaky Bucket**

```go
package main  
  
import (  
    "fmt"  
    "sync"    "time")  
  
// LeakyBucket реализует логику "дырявого ведра".type LeakyBucket struct {  
    queue   chan struct{} // Очередь запросов  
    ticker  *time.Ticker  // Тикер, определяющий скорость "утечки"  
    wg      sync.WaitGroup  
    stopped bool  
}  
  
// NewLeakyBucket создает и запускает новый LeakyBucket.  
// ratePerSec - количество запросов в секунду, которое может "утечь".  
// capacity - максимальный размер очереди (объем ведра).  
func NewLeakyBucket(ratePerSec int, capacity int) *LeakyBucket {  
    if ratePerSec <= 0 || capacity <= 0 {  
       return nil  
    }  
  
    lb := &LeakyBucket{  
       queue:  make(chan struct{}, capacity),  
       ticker: time.NewTicker(time.Second / time.Duration(ratePerSec)),  
    }  
  
    lb.wg.Add(1)  
    go lb.processor()  
  
    return lb  
}  
  
// processor - это горутина, которая "обрабатывает" запросы с постоянной скоростью.func (lb *LeakyBucket) processor() {  
    defer lb.wg.Done()  
    for range lb.ticker.C {  
       // При каждом тике мы "обрабатываем" один запрос из очереди.  
       // Если очередь пуста, эта операция просто ждёт следующего запроса.       <-lb.queue  
       fmt.Printf("[%s] Запрос обработан (утёк из ведра)\n", time.Now().Format("15:04:05.000"))  
    }  
}  
  
// Allow проверяет, можно ли добавить запрос в очередь.func (lb *LeakyBucket) Allow() bool {  
    if lb.stopped {  
       return false  
    }  
    // Используем select для неблокирующей отправки в канал.  
    select {  
    case lb.queue <- struct{}{}:  
       // Если удалось добавить в очередь, значит, запрос принят.  
       return true  
    default:  
       // Если очередь заполнена (канал заблокирован), запрос отклоняется.  
       return false  
    }  
}  
  
// Stop останавливает обработчик.func (lb *LeakyBucket) Stop() {  
    lb.stopped = true  
    lb.ticker.Stop()  
    // Закрываем канал, чтобы разблокировать processor, если он ждет  
    close(lb.queue)  
    lb.wg.Wait()  
}  
  
func main() {  
    // Создаем ведро: 2 запроса/сек, емкость 5.  
    bucket := NewLeakyBucket(2, 5)  
    defer bucket.Stop()  
  
    // Попробуем быстро отправить 10 запросов (создать всплеск).  
    fmt.Println("--- Отправка 10 запросов ---")  
    for i := 1; i <= 10; i++ {  
       if bucket.Allow() {  
          fmt.Printf("Запрос %d: ПРИНЯТ в очередь\n", i)  
       } else {  
          fmt.Printf("Запрос %d: ОТКЛОНЕН (ведро полное)\n", i)  
       }  
       time.Sleep(100 * time.Millisecond) // Небольшая пауза между попытками  
    }  
  
    // Ждем немного, чтобы увидеть, как оставшиеся в очереди запросы обрабатываются.  
    fmt.Println("\n--- Ожидание обработки оставшихся запросов ---")  
    time.Sleep(3 * time.Second)  
}
```