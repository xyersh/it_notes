
### Что это такое?
Ограничитель скорости контролирует количество событий, которые могут произойти за определенный период времени. Это полезно для предотвращения перегрузки системы, защиты от злоупотреблений (например, DoS-атак) или соблюдения ограничений внешних API.

Готовая реализация в Golang: golang.org/x/time/rate

**Основные цели и задачи, которые решает Rate Limiter:**
1. **Защита от перегрузки (Overload Protection):** Предотвращает исчерпание ресурсов сервера (ЦП, память, пропускная способность сети) из-за слишком большого количества одновременных запросов. Это защищает систему от замедления работы или полного отказа.
2. **Защита от злонамеренных действий:** Снижает эффективность DoS (Denial of Service) и DDoS-атак, а также попыток брутфорса (например, подбора пароля), ограничивая количество попыток входа в систему.
3. **Обеспечение справедливого использования (Fair Usage):** Гарантирует, что ни один пользователь или сервис не сможет "монополизировать" ресурсы, предоставляя всем клиентам равные возможности для доступа к системе.
4. **Соблюдение лимитов внешних API:** При работе со сторонними сервисами (например, API Google, Twitter, Stripe) часто существуют ограничения на количество запросов. Rate Limiter помогает вашему приложению не превышать эти квоты и избежать временной блокировки или штрафов.
5. **Управление затратами:** Если вы используете платные API, где каждый вызов стоит денег, ограничитель скорости помогает контролировать расходы.

Самые распространённые алгоритмы для реализации этого паттерна — **"Token Bucket" (Ведро с токенами)** и **"Leaky Bucket" (Дырявое ведро)**.

#### **"Token Bucket"** - суть алгоритма:
- Представьте себе ведро определённой ёмкости (`burst`).
- В это ведро с постоянной скоростью (`limit`) добавляются "токены".
- Чтобы выполнить операцию, горутина должна взять один токен из ведра.
- Если токенов в ведре нет, горутина должна либо подождать, пока появится новый токен, либо получить отказ.
- Ёмкость ведра (`burst`) позволяет справляться с кратковременными всплесками активности. Например, если лимит — 2 запроса в секунду, а `burst` — 10, система может мгновенно обработать 10 запросов, а затем будет обрабатывать не более 2 в секунду.




#### **"Leaky Backet"** - суть алгоритма:
Представьте себе обычное ведро, у которого в дне есть небольшое отверстие.
	-  **Входящий поток (Запросы):** Вы льёте в это ведро воду. Вода — это входящие запросы к вашей системе. Вы можете лить её быстро (всплеск трафика) или медленно.
	- **Ведро (Очередь):** Ведро имеет ограниченный объём. Это очередь (буфер) для запросов.
	- **Отверстие (Процессор):** Через отверстие вода вытекает с **постоянной, неизменной скоростью**, независимо от того, сколько воды в ведре (лишь бы оно не было пустым). Это ваш обработчик, который обрабатывает запросы с фиксированной скоростью.
	- **Переполнение (Отклонение запросов):** Если вы льёте воду слишком быстро и ведро наполняется до краёв, новая вода просто переливается через край и теряется. Это отклоненные запросы, для которых не нашлось места в очереди.

##### Как это работает в программировании
Алгоритм формализуется следующим образом:

1. Создаётся очередь фиксированного размера (FIFO — "первым пришёл, первым ушёл").
2. Когда поступает новый запрос, система проверяет, есть ли в очереди свободное место.
    - **Если место есть**, запрос добавляется в конец очереди.
    - **Если очередь заполнена**, запрос немедленно отклоняется (отбрасывается).
3. Независимый обработчик считывает запросы из начала очереди и обрабатывает их через **равные промежутки времени** (например, строго один запрос каждые 100 миллисекунд).

##### Ключевые характеристики

- **Постоянная скорость на выходе:** Главная особенность Leaky Bucket — он превращает любой, даже самый "рваный" и непредсказуемый входящий трафик в **абсолютно ровный и предсказуемый исходящий поток**.
- **Сглаживание всплесков:** В отличие от Token Bucket, который _позволяет_ обрабатывать всплески (пока есть токены), Leaky Bucket их _сглаживает_, заставляя ждать в очереди.
- **Гарантированная задержка:** Поскольку запросы помещаются в очередь, они неизбежно получают дополнительную задержку. Чем длиннее очередь, тем дольше может ждать запрос.

##### Преимущества:

- **Простота реализации.**
- **Предсказуемый поток:** Легко контролировать нагрузку на нижестоящие системы.
- **Полное сглаживание трафика.**

##### Недостатки:

- **Неэффективен для всплесков:** Если система временно свободна, она всё равно не сможет обработать всплеск запросов быстрее своей постоянной скорости. Token Bucket в этой ситуации справился бы лучше.
- **Запросы в очереди простаивают:** Ресурсы могут быть свободны, но запросы всё равно ждут своей очереди, обрабатываясь с фиксированным интервалом.

#### Сравнение **Leaky Bucket** и **Token Bucket**

| Критерий                | Leaky Bucket (Дырявое ведро)                                                                | Token Bucket (Ведро с токенами)                                                                        |
| ----------------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **Основной принцип**    | Регулирует **скорость вывода** (outflow)                                                    | Регулирует **скорость ввода** (inflow)                                                                 |
| **Обработка всплесков** | **Сглаживает** всплески. Трафик на выходе всегда ровный                                     | **Позволяет** всплески. Можно мгновенно израсходовать все токены                                       |
| **Основной ресурс**     | Размер очереди для ожидания                                                                 | Количество токенов для разрешения                                                                      |
| **Результат**           | Трафик становится предсказуемым и равномерным                                               | Пропускная способность соответствует заданным лимитам, но допускает "пики"                             |
| **Идеально для...**     | Систем, где важна постоянная скорость потребления ресурсов (например, стриминг видео/аудио) | Классических API, где нужно ограничить среднюю скорость, но разрешить кратковременные пики активности. |


### Примеры

#### простая реализации (с использованием `time.Ticker`):

```go
package main

import (
	"fmt"
	"time"
)

func processRequest(id int) {
	fmt.Printf("Обработка запроса %d в %s\n", id, time.Now().Format(time.RFC3339))
	time.Sleep(time.Millisecond * 200) // Имитация обработки
}

func main() {
	rate := time.Second / 2 // Разрешаем 2 запроса в секунду
	limiter := time.Tick(rate)

	for i := 1; i <= 5; i++ {
		<-limiter // Блокируемся до тех пор, пока не пройдет разрешенное время
		processRequest(i)
	}
}
```



#### Реализация Leaky Bucket


```go
package main  
  
import (  
    "fmt"  
    "sync"    "time")  
  
// LeakyBucket реализует логику "дырявого ведра".type LeakyBucket struct {  
    queue   chan struct{} // Очередь запросов  
    ticker  *time.Ticker  // Тикер, определяющий скорость "утечки"  
    wg      sync.WaitGroup  
    stopped bool  
}  
  
// NewLeakyBucket создает и запускает новый LeakyBucket.  
// ratePerSec - количество запросов в секунду, которое может "утечь".  
// capacity - максимальный размер очереди (объем ведра).  
func NewLeakyBucket(ratePerSec int, capacity int) *LeakyBucket {  
    if ratePerSec <= 0 || capacity <= 0 {  
       return nil  
    }  
  
    lb := &LeakyBucket{  
       queue:  make(chan struct{}, capacity),  
       ticker: time.NewTicker(time.Second / time.Duration(ratePerSec)),  
    }  
  
    lb.wg.Add(1)  
    go lb.processor()  
  
    return lb  
}  
  
// processor - это горутина, которая "обрабатывает" запросы с постоянной скоростью.func (lb *LeakyBucket) processor() {  
    defer lb.wg.Done()  
    for range lb.ticker.C {  
       // При каждом тике мы "обрабатываем" один запрос из очереди.  
       // Если очередь пуста, эта операция просто ждёт следующего запроса.       <-lb.queue  
       fmt.Printf("[%s] Запрос обработан (утёк из ведра)\n", time.Now().Format("15:04:05.000"))  
    }  
}  
  
// Allow проверяет, можно ли добавить запрос в очередь.func (lb *LeakyBucket) Allow() bool {  
    if lb.stopped {  
       return false  
    }  
    // Используем select для неблокирующей отправки в канал.  
    select {  
    case lb.queue <- struct{}{}:  
       // Если удалось добавить в очередь, значит, запрос принят.  
       return true  
    default:  
       // Если очередь заполнена (канал заблокирован), запрос отклоняется.  
       return false  
    }  
}  
  
// Stop останавливает обработчик.func (lb *LeakyBucket) Stop() {  
    lb.stopped = true  
    lb.ticker.Stop()  
    // Закрываем канал, чтобы разблокировать processor, если он ждет  
    close(lb.queue)  
    lb.wg.Wait()  
}  
  
func main() {  
    // Создаем ведро: 2 запроса/сек, емкость 5.  
    bucket := NewLeakyBucket(2, 5)  
    defer bucket.Stop()  
  
    // Попробуем быстро отправить 10 запросов (создать всплеск).  
    fmt.Println("--- Отправка 10 запросов ---")  
    for i := 1; i <= 10; i++ {  
       if bucket.Allow() {  
          fmt.Printf("Запрос %d: ПРИНЯТ в очередь\n", i)  
       } else {  
          fmt.Printf("Запрос %d: ОТКЛОНЕН (ведро полное)\n", i)  
       }  
       time.Sleep(100 * time.Millisecond) // Небольшая пауза между попытками  
    }  
  
    // Ждем немного, чтобы увидеть, как оставшиеся в очереди запросы обрабатываются.  
    fmt.Println("\n--- Ожидание обработки оставшихся запросов ---")  
    time.Sleep(3 * time.Second)  
}
```


#### Реализация Token Bucket
Мы создадим структуру `TokenBucket`, которая будет хранить своё состояние:

- `capacity` — максимальное количество токенов.
- `tokens` — текущее количество токенов.
- `rate` — скорость пополнения (токенов в секунду).
- `lastTokenTime` — время последнего пополнения токенов.
- `mu` — мьютекс для безопасной работы в конкурентной среде.

Основная логика будет заключаться в том, чтобы перед каждой попыткой взять токен сначала вычислить, сколько новых токенов должно было накопиться со времени последней операции.
```go 
package main

import (
	"fmt"
	"sync"
	"time"
)

// TokenBucket представляет наше "ведро с токенами".
type TokenBucket struct {
	capacity      int64 // Максимальная емкость ведра (burst)
	tokens        int64 // Текущее количество токенов в ведре

	rate          int64     // Скорость пополнения (токенов в секунду)
	lastTokenTime time.Time // Время последнего пополнения токенов
	mu            sync.Mutex
}

// NewTokenBucket создает новое ведро с токенами.
// rate - количество токенов, добавляемых в секунду.
// capacity - максимальное количество токенов в ведре.
func NewTokenBucket(rate, capacity int64) *TokenBucket {
	if rate <= 0 || capacity <= 0 {
		return nil
	}
	return &TokenBucket{
		capacity:      capacity,
		tokens:        capacity, // Начинаем с полного ведра
		rate:          rate,
		lastTokenTime: time.Now(),
	}
}

// refill — внутренний метод для пополнения токенов.
// Он вычисляет, сколько времени прошло с последнего пополнения,
// и добавляет соответствующее количество токенов.
func (tb *TokenBucket) refill() {
	now := time.Now()
	// Вычисляем время, прошедшее с последнего пополнения
	duration := now.Sub(tb.lastTokenTime)

	// Вычисляем, сколько токенов нужно добавить.
	// Используем наносекунды для точности.
	tokensToAdd := (duration.Nanoseconds() * tb.rate) / 1e9 // 1e9 наносекунд = 1 секунда

	if tokensToAdd > 0 {
		// Добавляем новые токены
		tb.tokens += tokensToAdd
		// Убеждаемся, что количество токенов не превышает емкость
		if tb.tokens > tb.capacity {
			tb.tokens = tb.capacity
		}
		// Обновляем время последнего пополнения
		tb.lastTokenTime = now
	}
}

// Take пытается взять один токен из ведра.
// Возвращает true, если токен успешно взят, и false в противном случае.
// Это неблокирующая операция.
func (tb *TokenBucket) Take() bool {
	// Блокируем для безопасного доступа к состоянию
	tb.mu.Lock()
	defer tb.mu.Unlock()

	// Перед тем как взять токен, пополняем ведро
	tb.refill()

	// Проверяем, есть ли хотя бы один токен
	if tb.tokens >= 1 {
		tb.tokens--
		return true
	}

	return false
}

// --- Демонстрация работы ---
func main() {
	// Создаем ведро: 2 токена в секунду, максимальная емкость 5.
	bucket := NewTokenBucket(2, 5)

	fmt.Printf("Создано ведро: rate=2, capacity=5. Текущее время: %s\n\n", time.Now().Format("15:04:05"))

	// 1. Демонстрация "всплеска" (burst)
	// Пытаемся быстро взять 7 токенов. Первые 5 должны пройти успешно, т.к. ведро полное.
	fmt.Println("--- Попытка взять 7 токенов подряд (демонстрация capacity) ---")
	for i := 1; i <= 7; i++ {
		if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
	}
	fmt.Println("---------------------------------------------------------")

	// 2. Демонстрация пополнения
	// Ждем 1 секунду. За это время должны добавиться 2 новых токена (т.к. rate=2).
	fmt.Printf("\nЖдем 1 секунду... Время: %s\n", time.Now().Format("15:04:05"))
	time.Sleep(1 * time.Second)
	fmt.Printf("Прошла 1 секунда. Время: %s\n\n", time.Now().Format("15:04:05"))

	fmt.Println("--- Попытка взять 3 токена после паузы ---")
	// Теперь пытаемся взять 3 токена. Первые 2 должны пройти, третий - нет.
	for i := 1; i <= 3; i++ {
		if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
	}
	fmt.Println("---------------------------------------------------------")

    // 3. Демонстрация того, что емкость не превышается
	fmt.Printf("\nЖдем 3 секунды... Время: %s\n", time.Now().Format("15:04:05"))
    time.Sleep(3 * time.Second) // За 3 секунды должно сгенерироваться 3*2=6 токенов
	fmt.Printf("Прошло 3 секунды. Время: %s\n\n", time.Now().Format("15:04:05"))

    fmt.Println("--- Попытка взять 6 токенов после долгой паузы ---")
    // Хоть и сгенерировалось 6 токенов, в ведре их будет только 5 (макс. емкость)
    for i := 1; i <= 6; i++ {
        if bucket.Take() {
			fmt.Printf("Запрос %d: УСПЕХ\n", i)
		} else {
			fmt.Printf("Запрос %d: ОТКАЗ (нет токенов)\n", i)
		}
    }
}
```

##### Разбор кода 

1. **`NewTokenBucket`**: Создаёт ведро и сразу же "наполняет" его до краёв (`tokens: capacity`). Это позволяет системе сразу же обработать всплеск запросов, равный ёмкости ведра.
    
2. **`refill()`**: Это самая важная часть. Она не запускается по таймеру, а вызывается "лениво" в момент запроса токена. Это эффективно, так как не тратит ресурсы, если система простаивает. Расчёт `(duration.Nanoseconds() * tb.rate) / 1e9` позволяет корректно обрабатывать любые промежутки времени и скорости.
    
3. **`Take()`**: Публичный метод. Он оборачивает логику в мьютекс, чтобы избежать гонок данных, вызывает `refill` для актуализации состояния и затем пытается взять токен.