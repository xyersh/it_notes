Планировщик Go — это сердце системы конкурентности Go. Он отвечает за эффективное выполнение ваших **горутин** (goroutines) на доступных ядрах процессора, используя модель **M-P-G**.

### G (Goroutine):

- Это **легковесная, конкурентная функция** (по сути, функция, которая выполняется параллельно с другими).
- Горутины не являются потоками операционной системы (ОС). Они намного легче, чем потоки ОС, и Go может запускать миллионы горутин.
	- Каждая горутина имеет свой собственный **стек**, который динамически растет и уменьшается по мере необходимости.
- Создается с помощью ключевого слова `go` (например, `go myFunction()`).

### P (Processor):

- Это **логический процессор** или **контекст выполнения**. `P` — это абстракция, которая связывает горутины с потоками ОС.
- Каждый `P` имеет свою **локальную очередь** горутин, готовых к выполнению.
- Количество `P` по умолчанию равно значению `GOMAXPROCS` (обычно количество ядер ЦП на вашей машине). Вы можете изменить его с помощью `runtime.GOMAXPROCS(n)`.
- `P` необходим для выполнения кода Go. Если `P` нет, горутины не могут быть запланированы.


### M (Machine):
    
- Это **поток операционной системы**. `M` — это то, что фактически выполняет код.        
- Каждый `M` должен быть привязан к `P`, чтобы выполнять горутины.
- `M` может переключаться между `P`, если один `P` блокируется (например, при выполнении системного вызова).
- Если `M` блокируется (например, при чтении из сети), планировщик может отвязать его от `P` и привязать новый `M` к этому `P`, чтобы продолжить выполнение других горутин.


### Очереди горутин:

- **Локальные очереди (Local Run Queues)**: 
	- У каждого `P` есть своя очередь горутин, которые готовы к выполнению. Это помогает уменьшить конкуренцию за блокировки. 
	- Все горутины в ней находятся в состоянии runnable
	- Максимальное количество горутин в очереди- 256 
	- Если локальная очередь переполняется, новые горутины помещаются в глобальную очередь.
	
- **Глобальная очередь (Global Run Queue)**: 
	- `P`  может брать горутины из глобальной очереди, если его локальная очередь пуста.
	- Горутины помещаются в глобальную очередь в следующих случаях:
		- Переполнение локальной очереди - 256 горутин
		- Запуск горутины из CGO. Когда новая горутина запускается из кода, написанного на C (с помощью CGO), она не может быть сразу помещена в локальную очередь
		- Создание из "системной" горутины. Некоторые горутины, создаваемые самим рантаймом Go (например, для сборщика мусора), могут быть помещены в глобальную очередь, чтобы не нарушать работу локальных очередей и обеспечить их доступность для пользовательских горутин.

### Work Stealing (Кража работы):

- Это ключевой механизм для балансировки нагрузки. Если `P` завершил все горутины в своей локальной очереди и в глобальной очереди, он не будет простаивать.
- Вместо этого, `P` будет **"красть" горутины** из локальных очередей других `P`, которые заняты. Это гарантирует, что все доступные `P` остаются занятыми, максимально используя ресурсы ЦП.

### Блокировка и разблокировка `M`:
- Если горутина на `M` блокируется (например, при выполнении системного вызова, который занимает много времени), `M` отвязывается от своего `P`. 
- Этот `P` затем может быть привязан к другому доступному `M` (или будет создан новый `M`), чтобы продолжить выполнение других горутин.
- Когда заблокированный `M` освобождается, он снова пытается найти свободный `P` для выполнения.

Когда горутина блокируется и переходит в состояние **Waiting** (ожидание), ее состояние и контекст сохраняются, и она **удаляется** с любого **M** (OS-потока) и **P** (логического процессора) планировщика Go.

Она "паркуется" (ставится на ожидание) в структуре данных, связанной с причиной блокировки.
#### Причины блокировки и места ожидания:

- **Ожидание на канале (`channel`)**: Если горутина блокируется при отправке или получении данных через канал, она помещается в одну из очередей ожидания (например, `sendq` или `recvq`), которые являются частью **самой структуры канала**.
- **Ожидание на примитивах синхронизации (`sync.Mutex`, `sync.WaitGroup`, `sync.Cond`)**: Горутина помещается в список ожидания, который является частью соответствующей структуры синхронизации.
- **Блокирующий системный вызов (System Call)**:
    - Для **асинхронного I/O** (например, сетевые операции) горутина блокируется, но **M** (поток ОС), на котором она работала, не блокируется, а возвращает свой **P** обратно в пул для запуска других горутин. Сама заблокированная горутина регистрируется в **сетевом поллере** (`NetPoller`) Go, который асинхронно ждет завершения операции ввода/вывода.
    - Для **синхронного I/O** (например, чтение из файла), **M** (поток ОС) может быть заблокирован. В этом случае Go-планировщик может отсоединить **P** от этого **M** и создать новый **M** или использовать свободный **M** для выполнения других горутин, которые были запланированы на этом **P**. Заблокированная горутина остается связанной с этим **M** до завершения системного вызова.

#### Цикл состояний горутины

Горутина проходит через несколько основных состояний в планировщике Go (GPM-модель):
1. **Runnable (Готова к запуску):** Горутина находится в очереди выполнения (**Run Queue**), ожидая выделения ей **P** и **M**.
2. **Running (Выполняется):** Горутина выполняется на **M**, которому выделен **P**.
3. **Waiting (Ожидание/Блокировка):** Горутина остановлена и ждет какого-либо события (завершения I/O, получения данных по каналу, освобождения мьютекса и т. д.). **В этом состоянии она не занимает ни M, ни P.**



### Handoff 
— это механизм, который позволяет **потоку ОС (M)**, который вот-вот заблокируется (например, при выполнении системного вызова), **передать свой логический процессор (P)** другому, свободному потоку ОС. Это предотвращает простой `P` и позволяет ему продолжать выполнять другие горутины, пока первый поток заблокирован.

**Как это работает**:
1. Горутина вызывает блокирующую операцию.
2. Планировщик отвязывает `P` от текущего `M`.
3. `P` либо привязывается к другому доступному `M` из пула, либо создается новый `M`.
4. Новый `M` начинает выполнять горутины из очереди этого `P`, пока старый `M` ждёт завершения блокирующей операции.
5. Когда старый `M` разблокируется, он возвращается в пул потоков и ищет свободный `P` для выполнения.


### Sysmon (System Monitor)
**Sysmon** — это системный монитор, который работает в отдельной горутине и выполняет критически важные задачи в фоновом режиме. Он "просыпается" каждые 10 мс и выполняет следующие функции:
- **Preemption (Принудительное переключение)**: Если горутина выполняется слишком долго (более 10 мс) без вызова функции, sysmon помечает её для прерывания. Это предотвращает "захват" процессора одной горутиной и обеспечивает справедливое распределение времени ЦП.
- **Netpoller**: sysmon проверяет, нет ли разблокированных операций I/O в netpoller'е (об этом ниже).
- **Garbage Collector**: sysmon запускает сборщик мусора, если это необходимо.
- **Stealing**: Если некоторые `P` простаивают, а у других есть горутины, sysmon может инициировать "кражу работы" (`work stealing`) для балансировки нагрузки.

### Thread pool

Это набор потоков ОС хранящихся и используемых рантаймом golang.
Основная цель пула потоков Go — это **эффективное мультиплексирование** большого количества **Goroutines (G)** на небольшом, контролируемом количестве **OS Threads (M)**.
- **Фиксированный Основной Пул:**
    - Go-рантайм изначально создает пул **M**, количество которых обычно равно значению переменной окружения **GOMAXPROCS** (по умолчанию, это число логических ядер CPU).
    - Каждый **M** в этом основном пуле связан с одним **P**. Горутины из очереди **P** выполняются на связанном **M**.
- **Динамическое Увеличение:**
    - Пул **M** не является строго фиксированным. Go-рантайм **динамически создает новые потоки M** при необходимости.
    - **Блокирующие Системные Вызовы:** Если горутина, работающая на **M**, выполняет **блокирующий системный вызов** (например, чтение с диска или вызов C-кода), который не может быть обработан асинхронно сетевым поллером Go, этот **M** будет заблокирован.
    - В этом случае планировщик **отсоединяет P** от блокированного **M** и либо **создает новый M**, либо берет свободный **M** из кэша, чтобы связать его с **P**. Это позволяет другим горутинам продолжать работу, пока исходный **M** ожидает завершения системного вызова.
- **Повторное Использование (Pooling/Кэширование):**
    - Когда горутина завершается или блокированный **M** освобождается после завершения системного вызова, **M** **не уничтожается**.
    - Вместо этого он возвращается в **кэш/пул бездействующих OS-потоков** (`idle M pool`) для повторного использования. Это позволяет Go избегать дорогостоящих системных вызовов для создания и уничтожения OS-потоков при каждой новой задаче, что значительно повышает производительность.

### Netpoller (Сетевой опросчик)

**Netpoller** — это ключевой компонент для обработки неблокирующих сетевых операций. Он является абстракцией над системными механизмами, такими как `epoll` (Linux), `kqueue` (macOS/BSD) или IOCP (Windows).

- **Как это работает**:
    1. Когда горутина выполняет неблокирующую операцию ввода-вывода (например, чтение из сокета), она не ждёт ответа. Вместо этого она передает свою задачу **netpoller'у** и "засыпает".
    2. **Netpoller** ждёт событий от ОС (например, "данные готовы к чтению"). Он не занимает поток ОС.
    3. Когда событие происходит, netpoller "будит" соответствующую горутину и помещает её в очередь.
    4. Горутина теперь готова к выполнению и будет запланирована на `P` для продолжения работы.

Таким образом, **Netpoller** позволяет тысячам горутин одновременно ожидать завершения сетевых операций, не блокируя потоки ОС. Это основа эффективной конкурентности Go для I/O-bound приложений.